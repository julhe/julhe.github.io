<!doctype html>
<html lang="en-us">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name="hugo-theme" content="Axiom 0.7.2">



  <link rel="icon" type="image/png" sizes="32x32" href="/">
  <link rel="icon" type="image/x-icon" href="/">
  <link rel="apple-touch-icon" href="/">
  <link rel="canonical" href="https://julhe.github.io/posts/baked-spatial-reflections/">
<link rel="preload" as="style" href="/bundle.css?v=1602182466" media="all">
<link rel="stylesheet" href="/bundle.css?v=1602182466" media="all">
<style>.cdata pre{color:#edf2f7;background-color:#2d3748}.cdata :not(pre)>code{color:#805ad5;background-color:#f7fafc}.chroma .err{color:#fed7d7;background-color:#9b2c2c}.chroma .hl{background-color:#4a5568}.chroma .ln{color:#a0aec0}.chroma .k,.chroma .kc,.chroma .kd,.chroma .kn,.chroma .kp,.chroma .kr{color:#63b3ed}.chroma .kt{color:#b794f4}.chroma .na{color:#f6e05e}.chroma .nb{color:#f6ad55}.chroma .nc{color:#fc8181}.chroma .no{color:#68d391}.chroma .nd{color:#fc8181}.chroma .ne{color:#fc8181}.chroma .nf{color:#f6ad55}.chroma .nt{color:#fc8181}.chroma .l{color:#b794f4}.chroma .dl,.chroma .ld,.chroma .s,.chroma .s2,.chroma .sa,.chroma .sb,.chroma .sc,.chroma .sd{color:#68d391}.chroma .se{color:#a0aec0}.chroma .s1,.chroma .sh,.chroma .si,.chroma .sr,.chroma .ss,.chroma .sx{color:#68d391}.chroma .il,.chroma .m,.chroma .mb,.chroma .mf,.chroma .mh,.chroma .mi,.chroma .mo{color:#b794f4}.chroma .o,.chroma .ow{color:#90cdf4}.chroma .p{color:#cbd5e0}.chroma .c,.chroma .c1,.chroma .ch,.chroma .cm,.chroma .cp,.chroma .cpf,.chroma .cs{color:#a0aec0}.chroma .ge{font-style:italic}.chroma .gs{font-weight:700}
</style>



<title>Baked Surface Reflections : Julian Heinken&#39;s Webpage</title>

<meta property="og:title" content="Baked Surface Reflections">
<meta property="og:site_name" content="Julian Heinken&#39;s Webpage">
<meta property="og:url" content="https://julhe.github.io/posts/baked-spatial-reflections/">
<link rel="image_src" href="https://julhe.github.io/">
<meta property="og:image" content="https://julhe.github.io/">
<meta property="og:image:width" content="">
<meta property="og:image:height" content="">
<meta property="og:type" content="article">
<meta property="og:locale" content="en_us">
<meta property="og:description" content="Fast Methode for spatial reflections, or indirect specular">
<meta name="description" content="Fast Methode for spatial reflections, or indirect specular">
<meta property="og:updated_time" content="2018-11-21T19:24:00Z">
<meta property="fb:app_id" content="">
<meta name="author" content="Unknown">
<meta property="article:author" content="https://julhe.github.io/">
<meta property="article:published_time" content="2018-11-21T19:24:00Z">
<meta property="article:modified_time" content="2018-11-21T19:24:00Z">
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Article",
  "headline": "Baked Surface Reflections",
  "alternativeHeadline": "Fast Methode for spatial reflections, or indirect specular",
  "url": "https://julhe.github.io/posts/baked-spatial-reflections/",
  "image": "https://julhe.github.io/",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://julhe.github.io/posts/baked-spatial-reflections/"
  },
  "description": "Fast Methode for spatial reflections, or indirect specular",
  "author": {
    "@type": "Person",
    "name": "Unknown"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Julian Heinken's Webpage",
    "logo": {
      "@type": "ImageObject",
      "url": "https://julhe.github.io/"
    }
  },
  "datePublished": "2018-11-21T19:24:00Z",
  "dateModified": "2018-11-21T19:24:00Z",
  "articleBody": "\u003cp\u003eFor Lucid Trips I\u0026rsquo;ve needed a fast technique to provide reflection to a water surface. Not only was the surface large, it was also a sphere. A single reflection probe didn\u0026rsquo;t looked so well. But what would happened if we use thousands instead of one? I\u0026rsquo;ve made a prototype in Unity:\u003c/p\u003e\n\u003chr\u003e\r\n\u003cvideo autoplay=\"autoplay\" loop=\"loop\" width=\"720\" height=\"405\"\u003e\r\n  \u003csource src=\"baked_reflection_many_refprobes.webm\" type=\"video/webm\"\u003e\r\n  Your browser does not support the video tag.\r\n\u003c/video\u003e \r\n\r\n\r\n\u003cfigure\u003e\r\n\u003cimg\r\nclass=\"mb-2 mx-auto leading-none shadow-xl\"\r\nsrc=\"/example_atlas.jpg\"\r\nalt=\"43\"\u003e\r\n\u003cfigcaption class=\"text-sm text-right text-raven-500\"\u003e\r\n\u003cp\u003e43\u003c/p\u003e\r\n\u003c/figcaption\u003e\r\n\u003c/figure\u003e\r\n\r\n\u003cp\u003eNot bad, huh?\u003c/p\u003e\n\u003ch1 id=\"reflections-by-the-surface\"\u003eReflections by the surface\u003c/h1\u003e\n\u003cp\u003eWhile this looks good enough, with this amount of probes it\u0026rsquo;s a engine meltdown. :fire: But there is a thing we can exploit here: the reflection probes share the same resolution and are placed in a deterministic way, we can put them into a single data structure. There are Cubemap arrays, which allow to store up tp ~400 reflection probes, but thats not enough for my case.\u003c/p\u003e\n\u003cp\u003eI went with a solution that unwraps the reflection probe on to a 2D texture by (ab)using \u003ca href=\"https://knarkowicz.wordpress.com/2014/04/16/octahedron-normal-vector-encoding/\"\u003eOctahedron Encoding\u003c/a\u003e which maps a normalized, three-dimensional vector onto a two dimensional one. One can just use this compressed two dimensional vector as a UV coordinate, after scaling it from [-1, 1] to [0,1]. This texture is placed into a giant atlas which contains all unwraped reflection probes for the object.\u003c/p\u003e\n\r\n\r\n\u003cfigure\u003e\r\n\u003cimg\r\nclass=\"mb-2 mx-auto leading-none shadow-xl\"\r\nsrc=\"/example_atlas.jpg\"\r\nalt=\"A reflection atlas\"\u003e\r\n\u003cfigcaption class=\"text-sm text-right text-raven-500\"\u003e\r\n\u003cp\u003eA reflection atlas with 64 hemi-octahedron encoded reflection probes\u003c/p\u003e\r\n\u003c/figcaption\u003e\r\n\u003c/figure\u003e\r\n\n\u003cp\u003eFor interpolation, each neighbor tile is sampled and interpolated in a bilinear fashion.\u003c/p\u003e\n\u003ch1 id=\"baking-the-atlas\"\u003eBaking the Atlas\u003c/h1\u003e\n\u003cp\u003eFor each slice:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eRender your target mesh in UV Layout and store world-position, normal and tangent into different rendertargets\u003c/li\u003e\n\u003cli\u003eUse those rendertargets to get the world positions for the cubemaps\u003c/li\u003e\n\u003cli\u003eRender the Cubemaps\u003c/li\u003e\n\u003cli\u003eBring the Cubemap into Tangent Space (= hemisphere points in the same direction as the surface it sits on).\u003c/li\u003e\n\u003cli\u003eConvert the hemisphere into a texture slice\u003c/li\u003e\n\u003cli\u003ePut the Flatted-hemisphere into atlas\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch1 id=\"sampling-the-atlas\"\u003eSampling the Atlas\u003c/h1\u003e\n\u003cp\u003eFor each pixel:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eObtain the slice position by the UV\u003c/li\u003e\n\u003cli\u003eGet the reflection ray\u003c/li\u003e\n\u003cli\u003eBring the ray into tangent space\u003c/li\u003e\n\u003cli\u003eConvert the ray into octahedron / texture coordinate\u003c/li\u003e\n\u003cli\u003eUse slice base position and ray to sample the 4 clostest slices and interpolate them.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eLook into the example implementation on \u003ca href=\"https://github.com/julhe/BakedReflectionsUnity\"\u003eGitHub\u003c/a\u003e for more details\u003c/p\u003e\n\u003ch1 id=\"results\"\u003eResults\u003c/h1\u003e\n\u003cvideo autoplay=\"autoplay\" loop=\"loop\" width=\"720\" height=\"405\"\u003e\r\n  \u003csource src=\"baked_reflection_lt.webm\" type=\"video/webm\"\u003e\r\n  Your browser does not support the video tag.\r\n\u003c/video\u003e \r\n\u003chr\u003e\r\n\u003cvideo autoplay=\"autoplay\" loop=\"loop\" width=\"720\" height=\"405\" \u003e\r\n  \u003csource src=\"baked_reflection_spnoza.mp4\" type=\"video/mp4\"\u003e\r\n  Your browser does not support the video tag.\r\n\u003c/video\u003e\r\n\u003ch1 id=\"limitations\"\u003eLimitations\u003c/h1\u003e\n\u003cp\u003eThis technique is rather memory heavy and may not offer the same quality as planar or raytraced reflections. It\u0026rsquo;s also not dynamic, altough one could update a few slices overtime. But since it\u0026rsquo;s rather low on computational load, it should be a good fit for low-end devices or VR (like shown above in Lucid Trips).\u003c/p\u003e\n\u003ch1 id=\"source\"\u003eSource\u003c/h1\u003e\n\u003cp\u003eThe example implentaion for Unity can be found on \u003ca href=\"https://github.com/julhe/BakedReflectionsUnity\"\u003eGitHub\u003c/a\u003e\u003c/p\u003e"
}
</script>

<link rel="preload" as="script" href="/bundle.js?v=1602182466">


</head>
<body>

  <header id="nav" class="header">
  <div class="ax-l-i max-w-6xl">
    <div class="ax-logo">
      <a class="block" href="/" title="Julian Heinken&#39;s Webpage"><span class="font-semibold text-raven-900">Julian Heinken's Webpage</span></a>
    </div>
    <div class="ax-user">
      <a class="p-2 w-8 h-8 block text-raven-500 hover:text-gray-800 focus:text-gray-800 focus:outline-none" target="_blank" rel="noopener nofollow" href="https://www.google.com/search?q=site:https://julhe.github.io/" title="Search">
        <svg class="fill-current" viewBox="0 0 32 32" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M2.67 12.804c0-5.6 4.544-10.134 10.133-10.134s10.134 4.544 10.134 10.134-4.544 10.133-10.134 10.133S2.67 18.393 2.67 12.804zm28.943 16.923l-8.868-8.868c4.287-5.3 3.68-13.012-1.378-17.57S8.564-1.066 3.75 3.75s-5.017 12.558-.46 17.618 12.28 5.665 17.57 1.378l8.868 8.868a1.33 1.33 0 0 0 2.231-.597c.123-.46-.008-.952-.345-1.29h0z"/></svg>

      </a>
      <a class="p-2 block text-base leading-none text-raven-500 hover:text-gray-800 focus:text-gray-800 focus:outline-none" href="/about">
        About
      </a>
      <a class="p-2 block text-base leading-none text-raven-500 hover:text-gray-800 focus:text-gray-800 focus:outline-none" href="/posts">
        Posts
      </a>
      <a class="p-2 block text-base leading-none text-raven-500 hover:text-gray-800 focus:text-gray-800 focus:outline-none" href="/showcase">
        Showcase
      </a>
    </div>
  </div>

  
</header>

  <main>
<div class="default-single">
  <div class="ax-title ax-l-o">
    <div class="ax-l-i max-w-680">
      <h1 class="post-title font-content-title font-normal leading-tight tracking-default text-40">Baked Surface Reflections</h1>

      <div class="ax-meta flex items-center mt-5">
        <div class="flex-grow min-w-0">
          <div class="flex items-center">
  <div class="flex-shrink-0">
    <img
    class="w-12 h-12 sm:w-14 sm:h-14 object-cover p-3px rounded-full border border-blue-300"
    src="data:image/svg&#43;xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMzIgMzIiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayI&#43;PHBhdGggZmlsbD0iI2VjZWZmMSIgZD0iTTAgMGgzMnYzMkgweiIvPjxwYXRoIGZpbGw9IiM0NTVhNjQiIGQ9Ik0yOS4zMDUgMjQuNDA3Yy0uNzk1LS42My0xLjc2NS0xLjA4LTIuODE2LTEuM0wyMS40NzYgMjIuMWExLjEzIDEuMTMgMCAwIDEtLjkwNS0xLjEydi0xLjE1Yy4zMjItLjQ1My42MjYtMS4wNTQuOTQ0LTEuNjgyLjI0Ny0uNDg3LjYyLTEuMjIuODA1LTEuNCAxLjAxNS0xLjAyIDEuOTk1LTIuMTY1IDIuMy0zLjY0LjI4My0xLjM4NS4wMDUtMi4xMTItLjMyMi0yLjY5NyAwLTEuNDYtLjA0Ni0zLjI5LS4zOS00LjYyLS4wNC0xLjgtLjM2OC0yLjgxNC0xLjE5LTMuNy0uNTgtLjYzLTEuNDM1LS43NzUtMi4xMjMtLjg5LS4yNy0uMDQ2LS42NDItLjEtLjc4LS4xODNDMTguNTk0LjM0NyAxNy40LjAyNSAxNS45NTIgMGMtMyAuMTIzLTYuNzEgMi4wNC03Ljk1IDUuNDU0LS4zODQgMS4wNC0uMzQ1IDIuNzQ3LS4zMTMgNC4xMmwtLjAzLjgyNWMtLjI5NS41NzYtLjU4NSAxLjMwNy0uMyAyLjY5Ny4zMDIgMS40OCAxLjI4MiAyLjYyNiAyLjMxNSAzLjY2LjE3LjE3NC41NS45MTQuODAyIDEuNDAzbC45NSAxLjY3NXYxLjE1YzAgLjU0Ni0uMzgyIDEuMDE3LS45IDEuMTJMNS41IDIzLjExYy0xLjA0NS4yMjItMi4wMTQuNjctMi44MDcgMS4yOThhMS4xNSAxLjE1IDAgMCAwLS40MjcuODA1IDEuMTQgMS4xNCAwIDAgMCAuMjkzLjg1OUM1Ljk3NSAyOS44MzggMTAuODczIDMyIDE2IDMyczEwLjAyNy0yLjE2IDEzLjQ0LTUuOTNhMS4xNCAxLjE0IDAgMCAwLS4xMzUtMS42NjR6Ii8&#43;PC9zdmc&#43;DQo="
    alt="Unknown">
  </div>
  <div class="flex-shrink-0 ml-2 leading-tight font-content-sans">
    <a class="block text-sm text-raven-800 hover:text-raven-900 hover:underline focus:underline" target="_blank" rel="noopener nofollow" title="Unknown" href="https://julhe.github.io/">Unknown</a>
    <time class="text-sm text-raven-500" datetime="2018-11-21T19:24:00Z">Nov 21, 2018 8:24PM</time>
  </div>
</div>

        </div>
        <div>
          <div class="flex items-center">
  <a class="flex-shrink-0 block text-raven-800 hover:text-raven-900" target="_blank" rel="noopener nofollow" title="Share on Twitter" href="https://twitter.com/intent/tweet?text=Baked%20Surface%20Reflections%20by%20%40%23%20https%3a%2f%2fjulhe.github.io%2fposts%2fbaked-spatial-reflections%2f"><svg class="w-6 h-6 fill-current" viewBox="0 0 32 32" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M32 6.078c-1.2.522-2.458.868-3.78 1.036 1.36-.812 2.398-2.088 2.886-3.626a13.11 13.11 0 0 1-4.16 1.588C25.742 3.794 24.026 3 22.154 3a6.56 6.56 0 0 0-6.556 6.562c0 .52.044 1.02.152 1.496-5.454-.266-10.28-2.88-13.522-6.862-.566.982-.898 2.106-.898 3.316a6.57 6.57 0 0 0 2.914 5.452 6.48 6.48 0 0 1-2.964-.808v.072c0 3.188 2.274 5.836 5.256 6.446-.534.146-1.116.216-1.72.216-.42 0-.844-.024-1.242-.112.85 2.598 3.262 4.508 6.13 4.57a13.18 13.18 0 0 1-8.134 2.798c-.538 0-1.054-.024-1.57-.1C2.906 27.93 6.35 29 10.064 29c12.072 0 18.672-10 18.672-18.668 0-.3-.01-.57-.024-.848C30.014 8.56 31.108 7.406 32 6.078z"/></svg>
</a>
  <a class="ml-3 flex-shrink-0 block text-raven-800 hover:text-raven-900" target="_blank" rel="noopener nofollow" title="Share on Facebook" href="https://www.facebook.com/dialog/share?app_id=&display=page&href=https%3a%2f%2fjulhe.github.io%2fposts%2fbaked-spatial-reflections%2f"><svg class="w-6 h-6 fill-current" viewBox="-7 -3.5 39 39" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M30.234 0H1.765C.8.001 0 .79 0 1.766v28.47C.001 31.2.79 32 1.766 32h15.328V19.625h-4.156V14.78h4.156v-3.564c0-4.134 2.523-6.384 6.21-6.384 1.766 0 3.284.13 3.726.2v4.32h-2.543c-2.006 0-2.394.953-2.394 2.352v3.085h4.797l-.625 4.844h-4.172V32h8.14C31.21 32 32 31.2 32 30.234V1.765C32 .8 31.21 0 30.234 0z"/></svg>
</a>
</div>

        </div>
      </div>
    </div>
  </div><div class="ax-content ax-l-o">
    <div class="ax-l-i max-w-680">
      <article class="cdata">
<p>For Lucid Trips I&rsquo;ve needed a fast technique to provide reflection to a water surface. Not only was the surface large, it was also a sphere. A single reflection probe didn&rsquo;t looked so well. But what would happened if we use thousands instead of one? I&rsquo;ve made a prototype in Unity:</p>
<hr>
<video autoplay="autoplay" loop="loop" width="720" height="405">
  <source src="baked_reflection_many_refprobes.webm" type="video/webm">
  Your browser does not support the video tag.
</video> 


<figure>
<img
class="mb-2 mx-auto leading-none shadow-xl"
src="/example_atlas.jpg"
alt="43">
<figcaption class="text-sm text-right text-raven-500">
<p>43</p>
</figcaption>
</figure>

<p>Not bad, huh?</p>
<h1 id="reflections-by-the-surface">Reflections by the surface</h1>
<p>While this looks good enough, with this amount of probes it&rsquo;s a engine meltdown. :fire: But there is a thing we can exploit here: the reflection probes share the same resolution and are placed in a deterministic way, we can put them into a single data structure. There are Cubemap arrays, which allow to store up tp ~400 reflection probes, but thats not enough for my case.</p>
<p>I went with a solution that unwraps the reflection probe on to a 2D texture by (ab)using <a href="https://knarkowicz.wordpress.com/2014/04/16/octahedron-normal-vector-encoding/">Octahedron Encoding</a> which maps a normalized, three-dimensional vector onto a two dimensional one. One can just use this compressed two dimensional vector as a UV coordinate, after scaling it from [-1, 1] to [0,1]. This texture is placed into a giant atlas which contains all unwraped reflection probes for the object.</p>


<figure>
<img
class="mb-2 mx-auto leading-none shadow-xl"
src="/example_atlas.jpg"
alt="A reflection atlas">
<figcaption class="text-sm text-right text-raven-500">
<p>A reflection atlas with 64 hemi-octahedron encoded reflection probes</p>
</figcaption>
</figure>

<p>For interpolation, each neighbor tile is sampled and interpolated in a bilinear fashion.</p>
<h1 id="baking-the-atlas">Baking the Atlas</h1>
<p>For each slice:</p>
<ol>
<li>Render your target mesh in UV Layout and store world-position, normal and tangent into different rendertargets</li>
<li>Use those rendertargets to get the world positions for the cubemaps</li>
<li>Render the Cubemaps</li>
<li>Bring the Cubemap into Tangent Space (= hemisphere points in the same direction as the surface it sits on).</li>
<li>Convert the hemisphere into a texture slice</li>
<li>Put the Flatted-hemisphere into atlas</li>
</ol>
<h1 id="sampling-the-atlas">Sampling the Atlas</h1>
<p>For each pixel:</p>
<ol>
<li>Obtain the slice position by the UV</li>
<li>Get the reflection ray</li>
<li>Bring the ray into tangent space</li>
<li>Convert the ray into octahedron / texture coordinate</li>
<li>Use slice base position and ray to sample the 4 clostest slices and interpolate them.</li>
</ol>
<p>Look into the example implementation on <a href="https://github.com/julhe/BakedReflectionsUnity">GitHub</a> for more details</p>
<h1 id="results">Results</h1>
<video autoplay="autoplay" loop="loop" width="720" height="405">
  <source src="baked_reflection_lt.webm" type="video/webm">
  Your browser does not support the video tag.
</video> 
<hr>
<video autoplay="autoplay" loop="loop" width="720" height="405" >
  <source src="baked_reflection_spnoza.mp4" type="video/mp4">
  Your browser does not support the video tag.
</video>
<h1 id="limitations">Limitations</h1>
<p>This technique is rather memory heavy and may not offer the same quality as planar or raytraced reflections. It&rsquo;s also not dynamic, altough one could update a few slices overtime. But since it&rsquo;s rather low on computational load, it should be a good fit for low-end devices or VR (like shown above in Lucid Trips).</p>
<h1 id="source">Source</h1>
<p>The example implentaion for Unity can be found on <a href="https://github.com/julhe/BakedReflectionsUnity">GitHub</a></p>

      </article>
      

      

    </div>
  </div>
</div>

  </main>
  <footer class="footer">
  <div class="ax-l-i max-w-6xl">
    <nav class="flex items-center justify-center">
    </nav>

    <div class="footer-copyright text-sm text-center text-gray-500 mt-4">
      &#169; -2020 Julian Heinken
    </div>
    <div class="text-sm sm:text-xs text-center text-gray-500 mt-2">
      Powered by <a href="https://www.axiomtheme.com/?utm_source=theme-footer&utm_medium=website&utm_campaign=referral">Axiom</a>
    </div>
  </div>
</footer>

<script src="/bundle.js?v=1602182466"></script>


</body>
</html>
